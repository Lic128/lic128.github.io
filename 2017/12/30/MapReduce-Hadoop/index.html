<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="原文连接：  MapReduce源码分析 Hadoop Map/Reduce教程 MapReduce 概述Map/Reduce是一个用于大规模数据处理的分布式计算模型， 它最初是由Google工程师设计并实现的。 其中对它的定义是， Map/Reduce是一个编程模型， 是一个用于处理和生成大规模数据集的相关的实现。 ">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce &amp;&amp; Hadoop">
<meta property="og:url" content="http://yoursite.com/2017/12/30/MapReduce-Hadoop/index.html">
<meta property="og:site_name" content="Rock of SisyPhus">
<meta property="og:description" content="原文连接：  MapReduce源码分析 Hadoop Map/Reduce教程 MapReduce 概述Map/Reduce是一个用于大规模数据处理的分布式计算模型， 它最初是由Google工程师设计并实现的。 其中对它的定义是， Map/Reduce是一个编程模型， 是一个用于处理和生成大规模数据集的相关的实现。 用户定义一个map函数来处理一个key/value对以生成一批中间的key/va">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://www.uml.org.cn/bigdata/images/201606076.png">
<meta property="og:image" content="http://www.uml.org.cn/bigdata/images/201606077.png">
<meta property="og:updated_time" content="2018-01-03T18:57:51.563Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MapReduce &amp;&amp; Hadoop">
<meta name="twitter:description" content="原文连接：  MapReduce源码分析 Hadoop Map/Reduce教程 MapReduce 概述Map/Reduce是一个用于大规模数据处理的分布式计算模型， 它最初是由Google工程师设计并实现的。 其中对它的定义是， Map/Reduce是一个编程模型， 是一个用于处理和生成大规模数据集的相关的实现。 用户定义一个map函数来处理一个key/value对以生成一批中间的key/va">
<meta name="twitter:image" content="http://www.uml.org.cn/bigdata/images/201606076.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/12/30/MapReduce-Hadoop/"/>





  <title>MapReduce && Hadoop | Rock of SisyPhus</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Rock of SisyPhus</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/30/MapReduce-Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liyan Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rock of SisyPhus">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MapReduce && Hadoop</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-30T20:27:40-08:00">
                2017-12-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>原文连接： </p>
<p><a href="http://www.uml.org.cn/bigdata/201606072.asp" target="_blank" rel="noopener">MapReduce源码分析</a></p>
<p><a href="http://hadoop.apache.org/docs/r1.0.4/cn/mapred_tutorial.html#Mapper" target="_blank" rel="noopener">Hadoop Map/Reduce教程</a></p>
<h2 id="MapReduce-概述"><a href="#MapReduce-概述" class="headerlink" title="MapReduce 概述"></a>MapReduce 概述</h2><p>Map/Reduce是一个用于大规模数据处理的分布式计算模型， 它最初是由Google工程师设计并实现的。 其中对它的定义是， Map/Reduce是一个编程模型， 是一个用于处理和生成大规模数据集的相关的实现。 用户定义一个map函数来处理一个key/value对以生成一批中间的key/value对， 再定义一个reduce函数将所有这些中间的有着相同key的values合并起来。 很多现实世界中的任务都可以用这个模型来表达。</p>
<h2 id="MapReduce工作原理"><a href="#MapReduce工作原理" class="headerlink" title="MapReduce工作原理"></a>MapReduce工作原理</h2><p>Map-Reduce框架的运作完全基于<key, value="">对， 即数据的输入是一批<key, value="">对， 只是有时候它们的类型不一样而已。 Key和value的类由于需要支持被序列化（serialize）操作， 所以它们必须要实现writeable接口， 而且key的类还必须实现WritableComparable接口， 使得可以让框架对数据集的执行排序操作。</key,></key,></p>
<p>基本原理及要点： 将数据交给不同的机器去处理， 数据划分， 结果归约。</p>
<ul>
<li>MapReduce是一种模式</li>
<li>Hadoop是一种框架。</li>
<li>Hadoop是一个实现了MapReduce模式的开源的分布式并行编程框架。</li>
</ul>
<p>在数据被分割之后通过Map函数的程序将数据映射成不同的区块， 分配给计算机机群处理达到分布式运算的效果， 再通过Reduce函数的程序将结果汇整， 从而输出开发者需要的结果。</p>
<p>MapReduce致力于解决大规模数据处理的问题， 因此再设计之初就考虑了数据的局部性原理， 利用局部性原理将整个问题分而治之。 MapReduce集群由普通PC机构成， 为无共享式架构。 在处理之前， 将数据集分布至各个节点。 处理时， 每个节点就近读取本地存储的数据处理， 将处理后的数据进行合并(combine)， 排序(shuffle and sort)后再分发(至reduce节点) 避免了大量数据的传输， 提高处理效率。 无共享式架构的另一个好处是配合赋值策略， 集群可以具有良好的容错性， 一部分节点的down机对集群的正常工作不会造成影响。</p>
<p>其中Map阶段， 当map task开始运算， 并产生中间数据后并非直接而简单的写入磁盘， 它首先利用内存buffer来对已经产生的buffer进行缓存， 并在内存buffer中进行一些预排序来优化整个map的性能。 而上图右边的reduce阶段则经历了三个阶段， 粉笔是Copy-&gt;Sort-&gt;Reduce。我们能明显的看出， 其中的Sort是采取的归并排序， 即merge sort。</p>
<p>Mapper的输出被排序之后， 就被划分给每个Reducer。 分块的总数目和一个作业的reduce任务的数目是一样的， 用户可以实现自定义的Partitioner来控制哪个key被分配给哪个reducer。</p>
<p>Reducer将与一个key关联的一组中间数值集规约为一个更小的数据值。用户可以自行设定一个作业中reduce任务的数目。</p>
<p>Reduce由三个主要阶段： shuffle， sort和reduce。</p>
<ul>
<li><p>Shuffle</p>
<p>Reducer的输入就是Mapper已经排好序的输出， 在这个阶段， 框架通过HTTP为每个Reduer获得所有Mapper输出中与之相关的分块。</p>
</li>
<li><p>Sort 这个阶段， 框架将按照key的值对Reducer的输入进行分组（因为不同mapper的输出中可能会有相同的key）。</p>
</li>
<li><p>Shuffle和Sort的两个阶段是同时进行的； map的输出也是一边被取回一边被合并的。</p>
</li>
</ul>
<p>一个Map-Reduce任务的执行过程以及数据输入输出的类型如下所示：</p>
<p>Map：<k1,v1> -&gt;list<k2,v2></k2,v2></k1,v1></p>
<p>Reduce：<k2,list<v2>&gt; -&gt;<k3,v3></k3,v3></k2,list<v2></p>
<p>这一部分具体请见代码实现。</p>
<h2 id="MapReduce框架结构"><a href="#MapReduce框架结构" class="headerlink" title="MapReduce框架结构"></a>MapReduce框架结构</h2><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><h4 id="JobTracker"><a href="#JobTracker" class="headerlink" title="JobTracker"></a>JobTracker</h4><p>JobTracker是一个master服务， JobTracker负责调度job的每一个子任务task运行于TaskTracker上， 并监控它们， 如果发现有失败的task就重新运行它。 一般情况下应该把JobTracker部署在单独的机器上。</p>
<h4 id="TaskTracker"><a href="#TaskTracker" class="headerlink" title="TaskTracker"></a>TaskTracker</h4><p>TaskTracker是运行于多个节点上的slaver服务。 TaskTracker则负责直接执行每一个task。 TaskTracker都需要运行在HDFS的DataNode上。</p>
<h4 id="JobClient"><a href="#JobClient" class="headerlink" title="JobClient"></a>JobClient</h4><p>每一个job都会在用户端通过JobClient类将应用程序以及配置餐宿和打包成jar文件存储在HDFS， 并把路径提交到JobTracker， 然后由JobTracker创建每一个Task(即MapTask和ReduceTask)并把它们分发到每个TaskTracker服务中去执行。</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><h4 id="Mapper-和-Reducer"><a href="#Mapper-和-Reducer" class="headerlink" title="Mapper 和 Reducer"></a>Mapper 和 Reducer</h4><p>运行于Hadoop的MapReduce应用程序最基本的组成部分包括一个Mapper和一个Reducer类， 以及一个创建JobConf的执行程序， 在一些应用还可以包括一个Combiner类， 它实际上也是一个Reducer的实现。</p>
<h4 id="JobIngress"><a href="#JobIngress" class="headerlink" title="JobIngress"></a>JobIngress</h4><p>JobClient提交job后， JobTracker会创建一个JobInProgress来跟踪和调度这个job， 并把它添加到job队列里。 JobInProgress会根据提及的job jar中定义的输入数据集（已分解成FileSplit）创建对应的一批TaskInProgress用于监控和调度MapTask， 同时在创建指定数目的TaskInProgress用于监控和调度ReduceTask， 缺省为一个ReduceTask。</p>
<h4 id="TaskInProgress"><a href="#TaskInProgress" class="headerlink" title="TaskInProgress"></a>TaskInProgress</h4><p>JobTracker启动任务时通过每一个TaskInProgress来来launchTask， 这时会把Task对象（即MapTask和ReduceTask）序列化写入相应的TaskTracker服务中 ， TaskTracker收到后会创建对应的TaskInProgress（此<em>TaskInProgress</em>实现非<em>JobTracker</em>中使用的<em>TaskInProgress</em>，作用类似）用于监控和调度该Task。启动具体的Task进程是通过TaskInProgress管理的TaskRunner对象来运行的。 TaskRunner会自动装载job jar， 并设置好环境变量后启动一个独立的java child进程来执行Task， 即MapTask或者ReduceTask， 但是它们不一定运行在统一个TaskTracker中。</p>
<h4 id="MapTask-和ReduceTask"><a href="#MapTask-和ReduceTask" class="headerlink" title="MapTask 和ReduceTask"></a>MapTask 和ReduceTask</h4><p>一个完整的job会自动依次执行Mapper、Combiner（在JobConf指定了Combiner时执行）和Reducer，其中Mapper和Combiner是由MapTask调用执行，Reducer则由ReduceTask调用，Combiner实际也是Reducer接口类的实现。Mapper会根据jobjar中定义的输入数据集按<key1,value1>对读入，处理完成生成临时的<key2,value2>对，如果定义了Combiner，MapTask会在Mapper完成调用该Combiner将相同key的值做合并处理，以减少输出结果集。MapTask的任务全完成即交给ReduceTask进程调用Reducer处理，生成最终结果<key3,value3>对。这个过程在下一部分再详细介绍。</key3,value3></key2,value2></key1,value1></p>
<p><img src="http://www.uml.org.cn/bigdata/images/201606076.png" alt=""></p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>一道MapRedcue作业是通过JobClient.rubJob(job)向master节点的JobTracker提交的, JobTracker接到JobClient的请求后把其加入作业队列中。JobTracker一直在等待JobClient通过RPC提交作业,而TaskTracker一直通过RPC向JobTracker发送心跳heartbeat询问有没有任务可做，如果有，让其派发任务给它执行。如果JobTracker的作业队列不为空, 则TaskTracker发送的心跳将会获得JobTracker给它派发的任务。这是一道pull过程。slave节点的TaskTracker接到任务后在其本地发起Task,执行任务。以下是简略示意图：</p>
<p><img src="http://www.uml.org.cn/bigdata/images/201606077.png" alt=""></p>
<h2 id="更多实现细节，-请看上面链接。"><a href="#更多实现细节，-请看上面链接。" class="headerlink" title="更多实现细节， 请看上面链接。"></a>更多实现细节， 请看上面链接。</h2><h2 id="HDFS-Basic-Concept"><a href="#HDFS-Basic-Concept" class="headerlink" title="HDFS Basic Concept"></a>HDFS Basic Concept</h2><h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h3><p>HDFS(Hadoop Distributed File System) 默认的最基本的存储单位是64M的数据块。</p>
<p>和普通文件系统相同的是， HDFS中的文件是被分成64M一块的数据块存储的。</p>
<p>不同于普通文件系统的是， HDFS中， 如果一个文件小于一个数据块的大小， 并不占用整个数据块存储空间。</p>
<h3 id="元数据节点（Namenode）和数据节点-datanode"><a href="#元数据节点（Namenode）和数据节点-datanode" class="headerlink" title="元数据节点（Namenode）和数据节点(datanode)"></a>元数据节点（Namenode）和数据节点(datanode)</h3><ul>
<li><p>元数据节点用来管理文件系统的命名空间</p>
<ul>
<li>其将所有的文件和文件夹的元数据保存在一个文件系统树中。</li>
<li>这些信息也会在硬盘上保存成以下文件： 命名空间镜像(namespace image)及修改日志(edit log).</li>
<li>其还保存了一个文件包括哪些数据块， 分布在哪些数据节点上， 然而这些信息并不存储在硬盘上， 而是在系统启动的时候从数据节点收集而成的。</li>
</ul>
</li>
<li><p>数据节点是文件系统中真正存储数据的地方。</p>
<ul>
<li>客户端或者元数据信息(namenode)可以向数据节点请求写入或者读出数据块。</li>
<li>其周期性的向元数据节点回报其存储的数据块信息。</li>
</ul>
</li>
<li><p>从元数据节点(secondary namenode)</p>
<ul>
<li>从元数据节点并不是元数据节点出现问题时候的备用节点， 它和元数据节点负责不同的事情。</li>
<li>其主要功能就是周期性地将元数据节点的命名空间镜像文件和修改日志合并， 以防日志文件过大， 这点会在下面叙述。</li>
</ul>
</li>
</ul>
<ul>
<li><p>合并过后的命名空间镜像也在元数据节点保存了一份， 以防元数据节点失败的时候， 可以回复。</p>
<p>​</p>
<p>​</p>
<p>​</p>
</li>
</ul>
<p>HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware. Let’s examine this statement in more detail:</p>
<ol>
<li><p>Very large files</p>
</li>
<li><p>Streaming data access.</p>
<p>HDFS is built around the idea that the most efficient data processing pattern is write-once, read-many-times pattern. A dataset is typically generated or copied from source, and then various analyses are performed on the dataset over time. Each analysis will involve a large proportion, if not all, of the dataset, so the time to read the whole dataset is more important than the latency in reading the first record.</p>
</li>
<li><p>Commodity hardware.</p>
<p>​</p>
<p>​</p>
<p>​</p>
<p>​</p>
</li>
</ol>
<p>Why is a Block in HDFS So Large?</p>
<p>HDFS blocks are large compared to disk blocks, and the reason is to minimize the cost of seeks. If the block is large enough, the time it takes to transfer the data from the disk can be significantly longer than the time to seek to the start of the block. Thus, transferring a large file made of multiple blocks operates at the disk transfer rate. A quick calculation shows that if the seek time is around 10 ms and the transfer rate is 100 MB/s, to make the seek time 1% of the transfer time, we need to make the block size around 100 MB. The default is actually 128 MB, although many HDFS installations use larger block sizes. This figure will continue to be revised upward as transfer speeds grow with new generations of disk drives. This argument shouldn’t be taken too far, however. Map tasks in MapReduce normally operate on one block at a time, so if you have too few tasks (fewer than nodes in the cluster), your jobs will run slower than they could otherwise.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/12/26/Detect-cycle-in-graph/" rel="next" title="Detect cycle in graph">
                <i class="fa fa-chevron-left"></i> Detect cycle in graph
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/01/Big-Data-Interview-Questions/" rel="prev" title="Big Data Interview Questions">
                Big Data Interview Questions <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Liyan Chen" />
            
              <p class="site-author-name" itemprop="name">Liyan Chen</p>
              <p class="site-description motion-element" itemprop="description">千江有水千江月， 万里无云万里天</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/Lic128" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:lic128@eng.ucsd.edu" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce-概述"><span class="nav-number">1.</span> <span class="nav-text">MapReduce 概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce工作原理"><span class="nav-number">2.</span> <span class="nav-text">MapReduce工作原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce框架结构"><span class="nav-number">3.</span> <span class="nav-text">MapReduce框架结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#角色"><span class="nav-number">3.1.</span> <span class="nav-text">角色</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#JobTracker"><span class="nav-number">3.1.1.</span> <span class="nav-text">JobTracker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TaskTracker"><span class="nav-number">3.1.2.</span> <span class="nav-text">TaskTracker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JobClient"><span class="nav-number">3.1.3.</span> <span class="nav-text">JobClient</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据结构"><span class="nav-number">3.2.</span> <span class="nav-text">数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper-和-Reducer"><span class="nav-number">3.2.1.</span> <span class="nav-text">Mapper 和 Reducer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JobIngress"><span class="nav-number">3.2.2.</span> <span class="nav-text">JobIngress</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TaskInProgress"><span class="nav-number">3.2.3.</span> <span class="nav-text">TaskInProgress</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapTask-和ReduceTask"><span class="nav-number">3.2.4.</span> <span class="nav-text">MapTask 和ReduceTask</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程"><span class="nav-number">3.3.</span> <span class="nav-text">流程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更多实现细节，-请看上面链接。"><span class="nav-number">4.</span> <span class="nav-text">更多实现细节， 请看上面链接。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-Basic-Concept"><span class="nav-number">5.</span> <span class="nav-text">HDFS Basic Concept</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据块"><span class="nav-number">5.1.</span> <span class="nav-text">数据块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#元数据节点（Namenode）和数据节点-datanode"><span class="nav-number">5.2.</span> <span class="nav-text">元数据节点（Namenode）和数据节点(datanode)</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyan Chen</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
